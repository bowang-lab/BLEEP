{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import config as CFG\n",
    "from models import CLIPModel, CLIPModel_ViT, CLIPModel_ViT_L, CLIPModel_CLIP, CLIPModel_resnet152, CLIPModel_resnet101\n",
    "from dataset import CLIPDataset\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the current scanpy version\n",
    "print(sc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_umap_clusters(expr_matrix, preprocess = True, normalize_and_log = True, batch_idx = None, n_neighbors=150, n_top_genes=1024, max_value=10, legend_loc='on data', show=False, save=False, save_name='umap_clusters.png'):\n",
    "    #! scanpy input matrix has cells as rows and genes as columns, same as this function\n",
    "    if preprocess:\n",
    "        # # Filter out genes with expression in less than 50 spots (for a ~8000 spot dataset over 4 slices)\n",
    "        # expressed = np.sum(expr_matrix>0, axis=0)\n",
    "        # expr_matrix = expr_matrix[:,expressed>50]\n",
    "\n",
    "        # Create AnnData object with batch index as an observation\n",
    "        adata = sc.AnnData(X=expr_matrix, dtype=expr_matrix.dtype)\n",
    "        if batch_idx is not None:\n",
    "            adata.obs['batch_idx'] = batch_idx\n",
    "\n",
    "        # Preprocess the data\n",
    "        if normalize_and_log:\n",
    "            sc.pp.normalize_total(adata)\n",
    "            sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)\n",
    "        print(\"n_top_genes: \", adata.var['highly_variable'].sum())\n",
    "        # sc.pp.scale(adata, max_value=max_value)\n",
    "    else:\n",
    "        adata = sc.AnnData(X=expr_matrix, dtype=expr_matrix.dtype)\n",
    "        if batch_idx is not None:\n",
    "            adata.obs['batch_idx'] = batch_idx\n",
    "\n",
    "    # Run UMAP and clustering on the preprocessed data\n",
    "    # sc.pp.scale(adata, max_value=max_value)\n",
    "    sc.pp.pca(adata, n_comps=50, use_highly_variable=preprocess)\n",
    "    sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=50)\n",
    "\n",
    "    sc.tl.umap(adata)\n",
    "    print(\"Running Leiden clustering\")\n",
    "    sc.tl.leiden(adata)\n",
    "    print(\"n_clusters: \", adata.obs['leiden'].nunique())\n",
    "    print(\"Plotting UMAP clusters\")\n",
    "\n",
    "    # Plot the UMAP embedding with cell clusters and batch index\n",
    "    if batch_idx is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        sc.pl.umap(adata, color='leiden', ax=ax, show=show, legend_loc=legend_loc)\n",
    "\n",
    "        # Save the figure\n",
    "        if save:\n",
    "            fig.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        return adata\n",
    "\n",
    "    else:\n",
    "        fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "        # Plot the UMAP embedding with cell clusters\n",
    "        sc.pl.umap(adata, color='leiden', ax=axs[0], show=False, legend_loc=legend_loc)\n",
    "\n",
    "        # Plot the UMAP embedding with batch information\n",
    "        sc.pl.umap(adata, color='batch_idx', ax=axs[1], show=False, legend_loc=legend_loc)\n",
    "\n",
    "\n",
    "        # Save the figure\n",
    "        if save:\n",
    "            fig.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "        return adata\n",
    "    \n",
    "\n",
    "def build_loaders_inference():\n",
    "    print(\"Building loaders\")\n",
    "    #(3467, 2378) (3467, 2349) (3467, 2277) (3467, 2265)\n",
    "    \n",
    "    dataset1 = CLIPDataset(image_path = \"~/GSE240429_data/images/GEX_C73_A1_Merged.tif\",\n",
    "                spatial_pos_path = \"~/GSE240429_data/data/tissue_pos_matrices/tissue_positions_list_1.csv\",\n",
    "                reduced_mtx_path = \"~/GSE240429_data/data/filtered_expression_matrices/1/harmony_matrix.npy\",\n",
    "                barcode_path = \"~/GSE240429_data/data/filtered_expression_matrices/1/barcodes.tsv\")\n",
    "    dataset2 = CLIPDataset(image_path = \"~/GSE240429_data/images/GEX_C73_B1_Merged.tif\",\n",
    "                spatial_pos_path = \"~/GSE240429_data/data/tissue_pos_matrices/tissue_positions_list_2.csv\",\n",
    "                reduced_mtx_path = \"~/GSE240429_data/data/filtered_expression_matrices/2/harmony_matrix.npy\",\n",
    "                barcode_path = \"~/GSE240429_data/data/filtered_expression_matrices/2/barcodes.tsv\")\n",
    "    dataset3 = CLIPDataset(image_path = \"~/GSE240429_data/images/GEX_C73_C1_Merged.tif\",\n",
    "                spatial_pos_path = \"~/GSE240429_data/data/tissue_pos_matrices/tissue_positions_list_3.csv\",\n",
    "                reduced_mtx_path = \"~/GSE240429_data/data/filtered_expression_matrices/3/harmony_matrix.npy\",\n",
    "                barcode_path = \"~/GSE240429_data/data/filtered_expression_matrices/3/barcodes.tsv\")\n",
    "    dataset4 = CLIPDataset(image_path = \"~/GSE240429_data/images/GEX_C73_D1_Merged.tif\",\n",
    "                spatial_pos_path = \"~/GSE240429_data/data/tissue_pos_matrices/tissue_positions_list_4.csv\",\n",
    "                reduced_mtx_path = \"~/GSE240429_data/data/filtered_expression_matrices/4/harmony_matrix.npy\",\n",
    "                barcode_path = \"~/GSE240429_data/data/filtered_expression_matrices/4/barcodes.tsv\")\n",
    "    \n",
    "    dataset = torch.utils.data.ConcatDataset([dataset1, dataset2, dataset3, dataset4])\n",
    "    test_loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "    print(\"Finished building loaders\")\n",
    "    return test_loader\n",
    "\n",
    "def get_image_embeddings(model_path, model):\n",
    "    test_loader = build_loaders_inference()\n",
    "    # model = CLIPModel().cuda()\n",
    "\n",
    "    state_dict = torch.load(model_path)\n",
    "    new_state_dict = {}\n",
    "    for key in state_dict.keys():\n",
    "        new_key = key.replace('module.', '')  # remove the prefix 'module.'\n",
    "        new_key = new_key.replace('well', 'spot') # for compatibility with prior naming\n",
    "        new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Finished loading model\")\n",
    "    \n",
    "    test_image_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            image_features = model.image_encoder(batch[\"image\"].cuda())\n",
    "            image_embeddings = model.image_projection(image_features)\n",
    "            test_image_embeddings.append(image_embeddings)\n",
    "    \n",
    "    return torch.cat(test_image_embeddings)\n",
    "\n",
    "\n",
    "def get_spot_embeddings(model_path, model):\n",
    "    test_loader = build_loaders_inference()\n",
    "    # model = CLIPModel().cuda()\n",
    "\n",
    "    state_dict = torch.load(model_path)\n",
    "    new_state_dict = {}\n",
    "    for key in state_dict.keys():\n",
    "        new_key = key.replace('module.', '')  # remove the prefix 'module.'\n",
    "        new_key = new_key.replace('well', 'spot') # for compatibility with prior naming\n",
    "        new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Finished loading model\")\n",
    "\n",
    "    spot_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            # spot_features = model.spot_encoder(batch[\"reduced_expression\"].cuda()) \n",
    "            # spot_embeddings = model.spot_projection(spot_features)\n",
    "            spot_embeddings.append(model.spot_projection(batch[\"reduced_expression\"].cuda()))\n",
    "    return torch.cat(spot_embeddings)\n",
    "\n",
    "\n",
    "#2265x256, 2277x256\n",
    "def find_matches(spot_embeddings, query_embeddings, top_k=1):\n",
    "    #find the closest matches \n",
    "    spot_embeddings = torch.tensor(spot_embeddings)\n",
    "    query_embeddings = torch.tensor(query_embeddings)\n",
    "    query_embeddings = F.normalize(query_embeddings, p=2, dim=-1)\n",
    "    spot_embeddings = F.normalize(spot_embeddings, p=2, dim=-1)\n",
    "    dot_similarity = query_embeddings @ spot_embeddings.T   #2277x2265\n",
    "    print(dot_similarity.shape)\n",
    "    _, indices = torch.topk(dot_similarity.squeeze(0), k=top_k)\n",
    "    \n",
    "    return indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs:\n",
    "#data sizes: (3467, 2378) (3467, 2349) (3467, 2277) (3467, 2265)\n",
    "\n",
    "\n",
    "datasize = [2378, 2349, 2277, 2265]\n",
    "model_path = \"result/best.pt\"\n",
    "save_path = \"result/embeddings/\"\n",
    "model = CLIPModel().cuda()\n",
    "\n",
    "\n",
    "img_embeddings_all = get_image_embeddings(model_path, model)\n",
    "spot_embeddings_all = get_spot_embeddings(model_path, model)\n",
    "\n",
    "img_embeddings_all = img_embeddings_all.cpu().numpy()\n",
    "spot_embeddings_all = spot_embeddings_all.cpu().numpy()\n",
    "print(img_embeddings_all.shape)\n",
    "print(spot_embeddings_all.shape)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "for i in range(4):\n",
    "    index_start = sum(datasize[:i])\n",
    "    index_end = sum(datasize[:i+1])\n",
    "    image_embeddings = img_embeddings_all[index_start:index_end]\n",
    "    spot_embeddings = spot_embeddings_all[index_start:index_end]\n",
    "    print(image_embeddings.shape)\n",
    "    print(spot_embeddings.shape)\n",
    "    np.save(save_path + \"img_embeddings_\" + str(i+1) + \".npy\", image_embeddings.T)\n",
    "    np.save(save_path + \"spot_embeddings_\" + str(i+1) + \".npy\", spot_embeddings.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#infer spot embeddings and expression\n",
    "spot_expression1 = np.load(\"filtered_expression_matrices/1/harmony_matrix.npy\")\n",
    "spot_expression2 = np.load(\"filtered_expression_matrices/2/harmony_matrix.npy\")\n",
    "spot_expression3 = np.load(\"filtered_expression_matrices/3/harmony_matrix.npy\")\n",
    "spot_expression4 = np.load(\"filtered_expression_matrices/4/harmony_matrix.npy\")\n",
    "\n",
    "save_path = \"result/embeddings/\"\n",
    "spot_embeddings1 = np.load(save_path + \"spot_embeddings_1.npy\")\n",
    "spot_embeddings2 = np.load(save_path + \"spot_embeddings_2.npy\")\n",
    "spot_embeddings3 = np.load(save_path + \"spot_embeddings_3.npy\")\n",
    "spot_embeddings4 = np.load(save_path + \"spot_embeddings_4.npy\")\n",
    "image_embeddings3 = np.load(save_path + \"img_embeddings_3.npy\")\n",
    "\n",
    "\n",
    "#query\n",
    "image_query = image_embeddings3\n",
    "expression_gt = spot_expression3\n",
    "spot_key = np.concatenate([spot_embeddings1, spot_embeddings2, spot_embeddings4], axis = 1)\n",
    "expression_key = np.concatenate([spot_expression1, spot_expression2, spot_expression4], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"average\"\n",
    "save_path = \"\"\n",
    "if image_query.shape[1] != 256:\n",
    "    image_query = image_query.T\n",
    "    print(\"image query shape: \", image_query.shape)\n",
    "if expression_gt.shape[0] != image_query.shape[0]:\n",
    "    expression_gt = expression_gt.T\n",
    "    print(\"expression_gt shape: \", expression_gt.shape)\n",
    "if spot_key.shape[1] != 256:\n",
    "    spot_key = spot_key.T\n",
    "    print(\"spot_key shape: \", spot_key.shape)\n",
    "if expression_key.shape[0] != spot_key.shape[0]:\n",
    "    expression_key = expression_key.T\n",
    "    print(\"expression_key shape: \", expression_key.shape)\n",
    "\n",
    "if method == \"simple\":\n",
    "    indices = find_matches(spot_key, image_query, top_k=1)\n",
    "    matched_spot_embeddings_pred = spot_key[indices[:,0],:]\n",
    "    print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "    matched_spot_expression_pred = expression_key[indices[:,0],:]\n",
    "    print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "if method == \"average\":\n",
    "    print(\"finding matches, using average of top 50 expressions\")\n",
    "    indices = find_matches(spot_key, image_query, top_k=50)\n",
    "    matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "    matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "    for i in range(indices.shape[0]):\n",
    "        matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0)\n",
    "        matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0)\n",
    "    \n",
    "    print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "    print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "if method == \"weighted_average\":\n",
    "    print(\"finding matches, using weighted average of top 50 expressions\")\n",
    "    indices = find_matches(spot_key, image_query, top_k=50)\n",
    "    matched_spot_embeddings_pred = np.zeros((indices.shape[0], spot_key.shape[1]))\n",
    "    matched_spot_expression_pred = np.zeros((indices.shape[0], expression_key.shape[1]))\n",
    "    for i in range(indices.shape[0]):\n",
    "        a = np.sum((spot_key[indices[i,0],:] - image_query[i,:])**2) #the smallest MSE\n",
    "        weights = np.exp(-(np.sum((spot_key[indices[i,:],:] - image_query[i,:])**2, axis=1)-a+1))\n",
    "        if i == 0:\n",
    "            print(\"weights: \", weights)\n",
    "        matched_spot_embeddings_pred[i,:] = np.average(spot_key[indices[i,:],:], axis=0, weights=weights)\n",
    "        matched_spot_expression_pred[i,:] = np.average(expression_key[indices[i,:],:], axis=0, weights=weights)\n",
    "    \n",
    "    print(\"matched spot embeddings pred shape: \", matched_spot_embeddings_pred.shape)\n",
    "    print(\"matched spot expression pred shape: \", matched_spot_expression_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "true = expression_gt\n",
    "pred = matched_spot_expression_pred\n",
    "\n",
    "print(pred.shape)\n",
    "print(true.shape)\n",
    "\n",
    "#genewise correlation\n",
    "corr = np.zeros(pred.shape[0])\n",
    "for i in range(pred.shape[0]):\n",
    "    corr[i] = np.corrcoef(pred[i,:], true[i,:],)[0,1]\n",
    "corr = corr[~np.isnan(corr)]\n",
    "print(\"Mean correlation across cells: \", np.mean(corr))\n",
    "\n",
    "corr = np.zeros(pred.shape[1])\n",
    "for i in range(pred.shape[1]):\n",
    "    corr[i] = np.corrcoef(pred[:,i], true[:,i],)[0,1]\n",
    "corr = corr[~np.isnan(corr)]\n",
    "print(\"number of non-zero genes: \", corr.shape[0])\n",
    "print(\"max correlation: \", np.max(corr))\n",
    "ind = np.argsort(np.sum(true, axis=0))[-50:]\n",
    "print(\"mean correlation highly expressed genes: \", np.mean(corr[ind]))\n",
    "ind = np.argsort(np.var(true, axis=0))[-50:]\n",
    "print(\"mean correlation highly variable genes: \", np.mean(corr[ind]))\n",
    "\n",
    "#marker genes\n",
    "marker_gene_list = [ \"HAL\", \"CYP3A4\", \"VWF\", \"SOX9\", \"KRT7\", \"ANXA4\", \"ACTA2\", \"DCN\"] #markers from macparland paper\n",
    "gene_names = pd.read_csv(\"~/GSE240429_data/data/filtered_expression_matrices/3/features.tsv\", header=None, sep=\"\\t\").iloc[:,1].values\n",
    "hvg_b = np.load(\"~/GSE240429_data/data/filtered_expression_matrices/hvg_union.npy\")\n",
    "marker_gene_ind = np.zeros(len(marker_gene_list))\n",
    "for i in range(len(marker_gene_list)):\n",
    "    marker_gene_ind[i] = np.where(gene_names[hvg_b] == marker_gene_list[i])[0]\n",
    "print(\"mean correlation marker genes: \", np.mean(corr[marker_gene_ind.astype(int)]))\n",
    "\n",
    "if save_path != \"\":\n",
    "    np.save(save_path + \"matched_spot_embeddings_pred.npy\", matched_spot_embeddings_pred.T)\n",
    "    np.save(save_path + \"matched_spot_expression_pred.npy\", matched_spot_expression_pred.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3467, 2277)\n",
      "(3467, 2277)\n"
     ]
    }
   ],
   "source": [
    "#construct heatmap of the GGC matrix\n",
    "expression_gt = np.load(\"~/GSE240429_data/data/filtered_expression_matrices/3/harmony_matrix.npy\")\n",
    "matched_spot_expression_pred_1 = np.load(\"result/embeddings/matched_spot_expression_pred.npy\")\n",
    "\n",
    "# matched_spot_expression_pred_2 = sc.read_h5ad('data/from_collab/harmony_C1_HisToGene_adata_pred.h5ad')\n",
    "# matched_spot_expression_pred_2 = matched_spot_expression_pred_2.X.T\n",
    "# matched_spot_expression_pred_3 = sc.read_h5ad('data/from_collab/harmony_C1_STNet_adata_pred.h5ad')\n",
    "# matched_spot_expression_pred_3 = matched_spot_expression_pred_3.X.T\n",
    "\n",
    "print(expression_gt.shape)\n",
    "print(matched_spot_expression_pred_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap of top 50 genes ranked by mean\n",
    "def plot_heatmap(expression_gt, matched_spot_expression_pred, top_k=50):\n",
    "    #take mean of expression\n",
    "    mean = np.mean(expression_gt, axis=1)\n",
    "    #take ind of top 100\n",
    "    ind = np.argpartition(mean, -top_k)[-top_k:]\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = np.corrcoef(expression_gt[ind,:])\n",
    "    dendrogram = hierarchy.dendrogram(hierarchy.linkage(corr_matrix, method='ward'), no_plot=True)\n",
    "    cluster_idx = dendrogram['leaves']\n",
    "\n",
    "    corr_matrix = np.corrcoef(matched_spot_expression_pred[ind,:])\n",
    "    corr_matrix = corr_matrix[cluster_idx, :]\n",
    "    corr_matrix = corr_matrix[:, cluster_idx]\n",
    "\n",
    "    # Reorder the correlation matrix and plot the heatmap\n",
    "    plt.figure(dpi=300, figsize=(5,5))\n",
    "    sns.heatmap(corr_matrix, cmap='viridis', xticklabels=False, yticklabels=False, cbar= False, vmin=-1, vmax=1)\n",
    "\n",
    "plot_heatmap(expression_gt, expression_gt, top_k=50)\n",
    "plot_heatmap(expression_gt, matched_spot_expression_pred_1, top_k=50)\n",
    "# plot_heatmap(expression_gt, matched_spot_expression_pred_2, top_k=50)\n",
    "# plot_heatmap(expression_gt, matched_spot_expression_pred_3, top_k=50)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
