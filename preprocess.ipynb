{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.io as sio\n",
    "import harmonypy as hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.3\n"
     ]
    }
   ],
   "source": [
    "#print the current scanpy version\n",
    "print(sc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36601, 2378)\n",
      "(36601, 2349)\n",
      "(36601, 2277)\n",
      "(36601, 2265)\n",
      "1000 1000\n",
      "1888 1000\n",
      "2703 1000\n",
      "Number of HVGs:  3467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#filter expression matrices to only include HVGs shared across all datasets\n",
    "def hvg_selection_and_pooling(exp_paths, n_top_genes = 1000):\n",
    "    #input n expression matrices paths, output n expression matrices with only the union of the HVGs\n",
    "\n",
    "    #read adata and find hvgs\n",
    "    hvg_bools = []\n",
    "    for d in exp_paths:\n",
    "        adata = sio.mmread(d)\n",
    "        adata = adata.toarray()\n",
    "        print(adata.shape)\n",
    "        adata = sc.AnnData(X=adata.T, dtype=adata.dtype)\n",
    "\n",
    "        # Preprocess the data\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)\n",
    "        \n",
    "        #save hvgs\n",
    "        hvg = adata.var['highly_variable']\n",
    "        hvg_bools.append(hvg)\n",
    "    \n",
    "    #find union of hvgs\n",
    "    hvg_union = hvg_bools[0]\n",
    "    for i in range(1, len(hvg_bools)):\n",
    "        print(sum(hvg_union), sum(hvg_bools[i]))\n",
    "        hvg_union = hvg_union | hvg_bools[i]\n",
    "\n",
    "    print(\"Number of HVGs: \", hvg_union.sum())\n",
    "\n",
    "    #filter expression matrices\n",
    "    filtered_exp_mtxs = []\n",
    "    for d in exp_paths:\n",
    "        adata = sio.mmread(d)\n",
    "        adata = adata.toarray()\n",
    "        adata = sc.AnnData(X=adata.T, dtype=adata.dtype)\n",
    "\n",
    "        # Preprocess the data and subset\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "        filtered_exp_mtxs.append(adata[:, hvg_union].X)\n",
    "    return filtered_exp_mtxs\n",
    "\n",
    "\n",
    "\n",
    "exp_paths = [\"~/GSE240429_data/data/filtered_expression_matrices/1/matrix.mtx\",\n",
    "            \"~/GSE240429_data/data/filtered_expression_matrices/2/matrix.mtx\",\n",
    "            \"~/GSE240429_data/data/filtered_expression_matrices/3/matrix.mtx\",\n",
    "            \"~/GSE240429_data/data/filtered_expression_matrices/4/matrix.mtx\"]\n",
    "\n",
    "filtered_mtx = hvg_selection_and_pooling(exp_paths)\n",
    "\n",
    "for i in range(len(filtered_mtx)):\n",
    "    np.save(\"~/GSE240429_data/data/filtered_expression_matrices/\" + str(i+1) +\"/hvg_matrix.npy\", filtered_mtx[i].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#! batch correct using harmony\n",
    "#! Other batch correction methods can be used here in place of harmony. Furthermore, model can be trained using the hvg matrix and achieve comparable results if the datasets used are similar enough\n",
    "\n",
    "d = np.load(\"~/GSE240429_data/data/filtered_expression_matrices/1/hvg_matrix.npy\")\n",
    "print(d.shape)\n",
    "\n",
    "d2 = np.load(\"~/GSE240429_data/data/filtered_expression_matrices/2/hvg_matrix.npy\")\n",
    "print(d2.shape)\n",
    "\n",
    "d3 = np.load(\"~/GSE240429_data/data/filtered_expression_matrices/3/hvg_matrix.npy\")\n",
    "print(d3.shape)\n",
    "\n",
    "d4 = np.load(\"~/GSE240429_data/data/filtered_expression_matrices/4/hvg_matrix.npy\")\n",
    "print(d4.shape)\n",
    "\n",
    "d = np.concatenate((d.T, d2.T, d3.T, d4.T), axis = 0)  \n",
    "\n",
    "data_sizes = [2378, 2349, 2277, 2265]\n",
    "batch_labels = np.concatenate((np.zeros(2378), np.ones(2349), np.ones(2277)*2, np.ones(2265)*3))\n",
    "batch_labels = batch_labels.astype(str)\n",
    "df = pd.DataFrame(batch_labels, columns=[\"dataset\"])\n",
    "\n",
    "# # Run the Harmony integration algorithm\n",
    "harmony = hm.run_harmony(d, meta_data=df, vars_use=[\"dataset\"])\n",
    "harmony_corrected = harmony.Z_corr.T\n",
    "\n",
    "#split back into datasets\n",
    "d1 = harmony_corrected[:data_sizes[0]]\n",
    "d2 = harmony_corrected[data_sizes[0]:data_sizes[0]+data_sizes[1]]\n",
    "d3 = harmony_corrected[data_sizes[0]+data_sizes[1]:data_sizes[0]+data_sizes[1]+data_sizes[2]]\n",
    "d4 = harmony_corrected[data_sizes[0]+data_sizes[1]+data_sizes[2]:]\n",
    "\n",
    "print(d1.shape, d2.shape, d3.shape, d4.shape)\n",
    "\n",
    "#save\n",
    "np.save(\"~/GSE240429_data/data/filtered_expression_matrices/1/harmony_matrix.npy\", d1.T)\n",
    "np.save(\"~/GSE240429_data/data/filtered_expression_matrices/2/harmony_matrix.npy\", d2.T)\n",
    "np.save(\"~/GSE240429_data/data/filtered_expression_matrices/3/harmony_matrix.npy\", d3.T)\n",
    "np.save(\"~/GSE240429_data/data/filtered_expression_matrices/4/harmony_matrix.npy\", d4.T)  #saving gene x cell to be consistent with hvg_matrix.npy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
